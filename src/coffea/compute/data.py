from abc import ABC, abstractmethod
from collections.abc import Iterator
from dataclasses import dataclass
from itertools import chain, repeat
from typing import Generic, Literal

import uproot
from more_itertools import roundrobin
from uproot import ReadOnlyDirectory

from coffea.compute.func import DirectoryFunc, EventsArray, EventsFunc, Processor
from coffea.compute.protocol import ResultT


@dataclass(frozen=True)
class StepElement:
    """A step element represents a chunk of events to be processed from a file.

    It is generated by any StepIterable implementation. It is supposed to live the duration
    of a task, but not serialized long-term.
    """

    file_path: str
    entry_range: tuple[int, int]

    def __len__(self) -> int:
        return self.entry_range[1] - self.entry_range[0]

    def load(self) -> EventsArray:
        # TODO: implementation of event loading
        info = str(self.entry_range)
        return info + "A" * (len(self) - len(info))


class StepIterable(ABC):
    @abstractmethod
    def iter_steps(self) -> Iterator[StepElement]:
        """Return an iterator over steps in the computation."""
        raise NotImplementedError

    def map_steps(
        self, func: EventsFunc[ResultT] | Processor[ResultT]
    ) -> "StepwiseComputable[ResultT]":
        """Apply a function or Processor to each step in this data."""
        if not callable(func):
            func = func.process
        return StepwiseComputable(func=func, iterable=self)


@dataclass(frozen=True)
class StepWorkElement(Generic[ResultT]):
    func: EventsFunc[ResultT]
    item: StepElement

    def __call__(self) -> ResultT:
        # TODO: where should we attach the metadata about the step parentship?
        # Here or in Step itself? Maybe in Step itself so that WorkElement can be generic?
        # Or maybe it should be here in StepWorkElement so that Step can remain lightweight
        # and not duplicate metadata contained inside the parent File or Dataset?
        return self.func(self.item.load())


@dataclass(frozen=True)
class StepwiseComputable(Generic[ResultT]):
    func: EventsFunc[ResultT]
    iterable: StepIterable

    def __iter__(self) -> Iterator[StepWorkElement[ResultT]]:
        return map(StepWorkElement, repeat(self.func), self.iterable.iter_steps())


@dataclass(frozen=True)
class FileElement:
    """A FileElement is a lightweight representation of a file to be loaded.

    It is generated by any FileIterable implementation. It is supposed to live the duration
    of a task, but not serialized long-term. For long-term storage, use File.
    """

    path: str

    def load(self) -> ReadOnlyDirectory:
        file = uproot.open(self.path)
        # assert isinstance(file, ReadOnlyDirectory)
        return file  # type: ignore[return-value]


class FileIterable(ABC):
    @abstractmethod
    def iter_files(self) -> Iterator[FileElement]:
        """Return an iterator over files in the computation."""
        raise NotImplementedError

    def map_files(self, func: DirectoryFunc[ResultT]) -> "FilewiseComputable[ResultT]":
        return FilewiseComputable(func=func, iterable=self)


@dataclass(frozen=True)
class FileWorkElement(Generic[ResultT]):
    func: DirectoryFunc[ResultT]
    item: FileElement

    def __call__(self) -> ResultT:
        return self.func(self.item.load())


@dataclass(frozen=True)
class FilewiseComputable(Generic[ResultT]):
    func: DirectoryFunc[ResultT]
    iterable: FileIterable

    def __iter__(self) -> Iterator[FileWorkElement[ResultT]]:
        return map(FileWorkElement, repeat(self.func), self.iterable.iter_files())


@dataclass
class File(StepIterable):
    path: str
    steps: list[tuple[int, int]]
    # TODO: object path within the file

    def iter_steps(self) -> Iterator[StepElement]:
        return map(StepElement, repeat(self.path), self.steps)


@dataclass
class Dataset(StepIterable, FileIterable):
    files: list[File]
    traversal: Literal["depth", "breadth"] = "depth"
    """The traversal strategy for iterating over files in the dataset.

    "depth" means to process all steps in one file before moving to the next file.
    "breadth" means to process the first step in all files, then the second step in all files, etc.
    """

    def iter_steps(self) -> Iterator[StepElement]:
        if self.traversal == "breadth":
            return roundrobin(*map(File.iter_steps, self.files))
        return chain.from_iterable(map(File.iter_steps, self.files))

    def iter_files(self) -> Iterator[FileElement]:
        return map(FileElement, (f.path for f in self.files))

    def __add__(self, other: "Dataset") -> "Dataset":
        return Dataset(files=self.files + other.files, traversal=self.traversal)


@dataclass
class DataGroup(StepIterable, FileIterable):
    datasets: dict[str, Dataset]
    traversal: Literal["depth", "breadth"] = "depth"
    """The traversal strategy for iterating over datasets in the group."""

    def iter_steps(self) -> Iterator[StepElement]:
        if self.traversal == "breadth":
            return roundrobin(*map(Dataset.iter_steps, self.datasets.values()))
        return chain.from_iterable(map(Dataset.iter_steps, self.datasets.values()))

    def iter_files(self) -> Iterator[FileElement]:
        if self.traversal == "breadth":
            return roundrobin(*map(Dataset.iter_files, self.datasets.values()))
        return chain.from_iterable(map(Dataset.iter_files, self.datasets.values()))

    def __add__(self, other: "DataGroup") -> "DataGroup":
        new_datasets = self.datasets.copy()
        new_datasets.update(other.datasets)
        return DataGroup(datasets=new_datasets, traversal=self.traversal)


@dataclass
class InputDataset(FileIterable):
    files: list[str]

    def iter_files(self) -> Iterator[FileElement]:
        return map(FileElement, self.files)


@dataclass
class InputDataGroup(FileIterable):
    datasets: dict[str, InputDataset]

    def iter_files(self) -> Iterator[FileElement]:
        return chain.from_iterable(map(InputDataset.iter_files, self.datasets.values()))
