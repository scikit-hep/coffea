from abc import ABC, abstractmethod
from collections.abc import Callable, Iterator
from dataclasses import dataclass
from functools import partial
from typing import Generic, TypeAlias

from coffea.compute.context import ContextDataElement, ContextInput, Ctx_co
from coffea.compute.data.workelement import MapData
from coffea.compute.func import EventsArray, Processor, process_chunk
from coffea.compute.protocol import ResultT

Chunk: TypeAlias = ContextInput[EventsArray, Ctx_co]
ChunkElement: TypeAlias = ContextDataElement[EventsArray, Ctx_co]


@dataclass(frozen=True)
class StepElement:
    """A step element represents a chunk of events to be processed from a file.

    It is generated by any StepIterable implementation. It is supposed to live the duration
    of a task, but not serialized long-term.
    """

    entry_range: tuple[int, int]
    file_path: str

    def __len__(self) -> int:
        return self.entry_range[1] - self.entry_range[0]

    def load(self) -> EventsArray:
        # TODO: implementation of event loading
        info = f"{self.entry_range},{self.file_path}"
        events = info + "A" * (len(self) - len(info))
        return events


class StepIterable(ABC, Generic[Ctx_co]):
    @abstractmethod
    def iter_steps(self) -> Iterator[ChunkElement[Ctx_co]]:
        """Return an iterator over steps in the computation."""
        raise NotImplementedError

    def map_steps(self, func: Callable[[Chunk[Ctx_co]], ResultT] | Processor[ResultT]):
        """Apply a function or Processor to each step in this data."""
        if not callable(func):
            func = partial(process_chunk, func)
        return MapData(func=func, make_iter=self.iter_steps)


__all__ = [
    "StepIterable",
    "StepElement",
]
